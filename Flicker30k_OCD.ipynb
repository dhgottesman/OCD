{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yS4DZqrQNA9S7yLdmLD8yOYJQFamCUpm",
      "authorship_tag": "ABX9TyOIpJpjSpg+nCzA4Jgvs+nh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhgottesman/OCD/blob/daniela_colab_dataloader/Flicker30k_OCD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIu_2kO5D2VO",
        "outputId": "8e00f722-c775-495c-cc3e-2472d02b5a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'X-VLM'...\n",
            "remote: Enumerating objects: 334, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 334 (delta 77), reused 70 (delta 70), pack-reused 242\u001b[K\n",
            "Receiving objects: 100% (334/334), 13.90 MiB | 41.02 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zengyan-97/X-VLM.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd X-VLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZRnhldxb01-",
        "outputId": "ce9042db-152d-4c65-82e6-cca8efb868c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/X-VLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt\n",
        "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCCxs9ywD3uQ",
        "outputId": "d142a313-8cd6-4f19-d5d7-b86c3516fd15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.4.9\n",
            "  Downloading timm-0.4.9-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting transformers==4.12.5\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 72.7 MB/s \n",
            "\u001b[?25hCollecting ruamel_yaml\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 78.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.6.0.66)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.2.2)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 15 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 77.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.0.6)\n",
            "Collecting pycocoevalcap\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 104.3 MB 142 kB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 89.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 80.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->-r requirements.txt (line 7)) (4.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2->-r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.12.5->-r requirements.txt (line 2)) (3.0.9)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.12.5->-r requirements.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5->-r requirements.txt (line 2)) (2022.9.24)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.5->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.5->-r requirements.txt (line 2)) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d4f8c3b8d4259dada018016aaf30463a175f2a3ad2879a5d43825cdfaa9d8728\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: torch, torchvision, tokenizers, sacremoses, ruamel.yaml.clib, huggingface-hub, transformers, timm, ruamel-yaml, pycocoevalcap\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed huggingface-hub-0.11.0 pycocoevalcap-1.2 ruamel-yaml-0.17.21 ruamel.yaml.clib-0.2.7 sacremoses-0.0.53 timm-0.4.9 tokenizers-0.10.3 torch-1.7.1 torchvision-0.8.2 transformers-4.12.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 122.1 MB/s eta 0:00:10tcmalloc: large alloc 1147494400 bytes == 0x395b8000 @  0x7eff12a2f615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 112.0 MB/s eta 0:00:09tcmalloc: large alloc 1434370048 bytes == 0x7dc0e000 @  0x7eff12a2f615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 114.4 MB/s eta 0:00:07tcmalloc: large alloc 1792966656 bytes == 0x2a40000 @  0x7eff12a2f615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████▎       | 1546.8 MB 130.1 MB/s eta 0:00:04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.1 MB/s eta 0:05:12tcmalloc: large alloc 2241208320 bytes == 0x6d828000 @  0x7eff12a2f615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf318a000 @  0x7eff12a2e1e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x1e1106000 @  0x7eff12a2f615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.4 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 91.1 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.7.1\n",
            "    Uninstalling torch-1.7.1:\n",
            "      Successfully uninstalled torch-1.7.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.8.2\n",
            "    Uninstalling torchvision-0.8.2:\n",
            "      Successfully uninstalled torchvision-0.8.2\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlvqLkznm30l",
        "outputId": "ef7d663a-e764-45ba-d195-f9351c68cbfc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPlMiUGkEBle",
        "outputId": "b101ae0a-070c-46e6-bce8-fd4060dfa000"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/X-VLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d hsankesara/flickr-image-dataset"
      ],
      "metadata": {
        "id": "xAGqLJBpU1pw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b99e8576-fdf5-4348-d530-ec5008649982"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-767a7d0a-b0ed-4cb8-a927-8f9d087ed639\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-767a7d0a-b0ed-4cb8-a927-8f9d087ed639\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading flickr-image-dataset.zip to /content/X-VLM\n",
            "100% 8.15G/8.16G [00:46<00:00, 170MB/s]\n",
            "100% 8.16G/8.16G [00:46<00:00, 189MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"flickr-image-dataset.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"images/\")"
      ],
      "metadata": {
        "id": "QUdxQzcsY5CU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"images/flickr30k_images/flickr30k_images/\" \"images/flickr30k-images/\"\n",
        "!rm -rf \"images/flickr30k-images/flickr30k_images/\""
      ],
      "metadata": {
        "id": "LjvOetPhwe94"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "with tarfile.open(\"/content/drive/MyDrive/Colab Notebooks/DL1/finetune.tar\") as tar:\n",
        "    tar.extractall(\"data\")"
      ],
      "metadata": {
        "id": "357yv6c4xzKd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/DL1/checkpoint_best.pth\" \"checkpoints/\""
      ],
      "metadata": {
        "id": "MaezvYMlblnW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output\n",
        "!mkdir output/itr_flickr"
      ],
      "metadata": {
        "id": "qx5Mv4rWAtfw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python3 run.py --task \"itr_flickr\" --dist \"gpu0\" --evaluate --output_dir \"output/itr_flickr\" --checkpoint \"/content/X-VLM/checkpoints/checkpoint_best.pth\"\n",
        "\n"
      ],
      "metadata": {
        "id": "0Xo_MrgjEEh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acfa488-a5f4-4ffa-e218-cc7c434ef76b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNODES,  1\n",
            "NPROC_PER_NODE,  8\n",
            "MASTER_ADDR,  SET_IT\n",
            "MASTER_PORT,  12345\n",
            "NODE_RANK,  0\n",
            "### warning: the settings for distributed training is not filled (ignore this if you only use one node)\n",
            "### warning: you have not set the path to hadoop_bin (ignore this if you don't use HDFS)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:164: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  \"The module torch.distributed.launch is deprecated \"\n",
            "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
            "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
            "  entrypoint       : Retrieval.py\n",
            "  min_nodes        : 1\n",
            "  max_nodes        : 1\n",
            "  nproc_per_node   : 1\n",
            "  run_id           : none\n",
            "  rdzv_backend     : static\n",
            "  rdzv_endpoint    : 127.0.0.1:29500\n",
            "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
            "  max_restarts     : 3\n",
            "  monitor_interval : 5\n",
            "  log_dir          : None\n",
            "  metrics_cfg      : {}\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_brrj0ipb/none_ey233tyt\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=0\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_brrj0ipb/none_ey233tyt/attempt_0/0/error.json\n",
            "2022-11-24 11:53:01.074301: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "| distributed init (rank 0): env://\n",
            "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
            "Creating model\n",
            "load checkpoint from /content/X-VLM/checkpoints/checkpoint_best.pth\n",
            "missing_keys:  []\n",
            "unexpected_keys:  []\n",
            "### Total Params:  213959547\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 350kB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 25.3kB/s]\n",
            "Downloading: 100% 455k/455k [00:01<00:00, 407kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 553kB/s]\n",
            "Creating retrieval dataset\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:835: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "### output_dir,  output/itr_flickr\n",
            "Start evaluating\n",
            "### be careful: func create_loader returns a list length of 1\n",
            "Computing features for evaluation...\n",
            "Evaluation: [   0/1000]  eta: 0:00:13    time: 0.0135  data: 0.0009  max mem: 3803\n",
            "Evaluation: [  50/1000]  eta: 0:00:20    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 100/1000]  eta: 0:00:19    time: 0.0213  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 150/1000]  eta: 0:00:18    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 200/1000]  eta: 0:00:17    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 250/1000]  eta: 0:00:16    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 300/1000]  eta: 0:00:14    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 350/1000]  eta: 0:00:13    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 400/1000]  eta: 0:00:12    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 450/1000]  eta: 0:00:11    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 500/1000]  eta: 0:00:10    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 550/1000]  eta: 0:00:09    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 600/1000]  eta: 0:00:08    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 650/1000]  eta: 0:00:07    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 700/1000]  eta: 0:00:06    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 750/1000]  eta: 0:00:05    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 800/1000]  eta: 0:00:04    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 850/1000]  eta: 0:00:03    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 900/1000]  eta: 0:00:02    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 173, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 169, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 624, in run\n",
            "    )(*cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 116, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 238, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 700, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 828, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../\n",
        "!pwd \n",
        "!git clone https://github.com/ShaharLutatiPersonal/OCD.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pqYKbuJDc6c",
        "outputId": "a55a7d91-048a-44c0-aa3a-ef44e019c790"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n",
            "Cloning into 'OCD'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 130 (delta 22), reused 19 (delta 19), pack-reused 102\u001b[K\n",
            "Receiving objects: 100% (130/130), 69.58 MiB | 46.93 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd X-VLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQE_xc16EMkJ",
        "outputId": "d06e02dc-6c4b-4817-8511-c73a301d1971"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/X-VLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_func_OCD.py -e 1 -t 0 -pc \"/content/X-VLM/configs/Retrieval_flickr_OCD.yaml\" -dt \"flickr30k\" -pd /content/X-VLM/checkpoints/checkpoint_best.pth -ps /content/X-VLM/checkpoints/checkpoint_best.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwglmLKqEWqb",
        "outputId": "0fd8275e-07c5-4ef5-e32a-58dce4666604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-24 14:50:57.999065: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "NNODES,  1\n",
            "NPROC_PER_NODE,  8\n",
            "MASTER_ADDR,  SET_IT\n",
            "MASTER_PORT,  12345\n",
            "NODE_RANK,  0\n",
            "Namespace(backbone_path='./base_models/checkpoint_tinynerf.pt', config_path='/content/X-VLM/configs/Retrieval_flickr_OCD.yaml', data_test_path='/data', data_train_path='./data/tiny_nerf_data.npz', datatype='flickr30k', diffusion_model_path='/content/X-VLM/checkpoints/checkpoint_best.pth', eval=1, learning_rate=0.0002, precompute_all=1, resume_training=0, scale_model_path='/content/X-VLM/checkpoints/checkpoint_best.pth', tensorboard_path='./logs', train=0)\n",
            "{'task': 'itr_flickr', 'dist': 'gpu0', 'evaluate': False, 'output_dir': 'output/itr_flickr', 'checkpoint': '/content/X-VLM/checkpoints/checkpoint_best.pth', 'bs:\"\"': None}\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:835: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "train 0.0\n",
            "train 1.0\n",
            "train 2.0\n",
            "train 3.0\n",
            "train 4.0\n",
            "train 5.0\n",
            "train 6.0\n",
            "train 7.0\n",
            "train 8.0\n",
            "train 9.0\n",
            "train 10.0\n",
            "train 11.0\n",
            "train 12.0\n",
            "train 13.0\n",
            "train 14.0\n",
            "train 15.0\n",
            "train 16.0\n",
            "train 17.0\n",
            "train 18.0\n",
            "train 19.0\n",
            "train 20.0\n",
            "train 21.0\n",
            "train 22.0\n",
            "train 23.0\n",
            "train 24.0\n",
            "train 25.0\n",
            "train 26.0\n",
            "train 27.0\n",
            "train 28.0\n",
            "train 29.0\n",
            "train 30.0\n",
            "train 31.0\n",
            "train 32.0\n",
            "train 33.0\n",
            "train 34.0\n",
            "train 35.0\n",
            "train 36.0\n",
            "train 37.0\n",
            "train 38.0\n",
            "train 39.0\n",
            "train 40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python run_func_OCD.py -e 1 -t 0 -pd ./checkpoints/model_ocd_tinynerf.pt -ps ./checkpoints/scale_model_tinynerf.pt\n"
      ],
      "metadata": {
        "id": "2WEtFo8LIJHl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd OCD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_eGKxNujm6k",
        "outputId": "60815bc9-296f-4612-f713-23a9cc372c9c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/XVLMDIR/OCD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf models"
      ],
      "metadata": {
        "id": "C4k08nlNjnsj"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"../models\" \"./models\"\n"
      ],
      "metadata": {
        "id": "LlP8Z803jy5i"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp run_func_OCD.py ../"
      ],
      "metadata": {
        "id": "C2QnuJsLlIZZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -r OCD/configs/ ./OCD_configs"
      ],
      "metadata": {
        "id": "Xtl7nGl2mS7P"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "a7A0U1uim1aw",
        "outputId": "014e10c6-9e18-4ff6-acb6-4fa4c4695eee"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/XVLMDIR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/XVLMDIR/configs/Retrieval_flickr.yaml /content/XVLMDIR/configs/Retrieval_flickr_OCD.yaml"
      ],
      "metadata": {
        "id": "_uYudQQqplo6"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ../OCD/data_loader.py ../OCD/diffusion_ocd.py ../OCD/ema.py ../OCD/run_func_OCD.py ../OCD/train.py ../OCD/utils_OCD.py     ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H0UyMiXpp7E",
        "outputId": "7221a2d3-6b9f-406a-be6b-5e76c938fb78"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: -r not specified; omitting directory '../OCD/nerf_utils/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ../OCD/nerf_utils ."
      ],
      "metadata": {
        "id": "2RmGDBPN7f9H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp configs/Retrieval_flickr.yaml configs/Retrieval_flickr_OCD.yaml"
      ],
      "metadata": {
        "id": "cdiVxNdO78IY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "p6S1s-Ni8Hc1",
        "outputId": "6f026db2-2600-4a3b-beac-85c4f52f58ee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/X-VLM'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp ../OCD/Lenet5.py ."
      ],
      "metadata": {
        "id": "vvVlsbMM8Ilo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sseCBaIF-3cd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}