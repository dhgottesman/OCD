{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yS4DZqrQNA9S7yLdmLD8yOYJQFamCUpm",
      "authorship_tag": "ABX9TyMbQlpWfYLt9gXc8VnF4fF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhgottesman/OCD/blob/daniela_init/Flicker30k_OCD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIu_2kO5D2VO",
        "outputId": "9d55c28e-2e6f-49ba-9341-b69bcff79da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'X-VLM'...\n",
            "remote: Enumerating objects: 334, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 334 (delta 77), reused 70 (delta 70), pack-reused 242\u001b[K\n",
            "Receiving objects: 100% (334/334), 13.90 MiB | 46.82 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zengyan-97/X-VLM.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd X-VLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZRnhldxb01-",
        "outputId": "e3a60380-0808-43fa-a686-d9f72e12a718"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/X-VLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt\n",
        "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCCxs9ywD3uQ",
        "outputId": "45541d44-aa62-47c1-bcdd-9fa2f74ea74e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.4.9\n",
            "  Downloading timm-0.4.9-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting transformers==4.12.5\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 25.2 MB/s \n",
            "\u001b[?25hCollecting ruamel_yaml\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 86.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.6.0.66)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.2.2)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 14 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.0.6)\n",
            "Collecting pycocoevalcap\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 104.3 MB 135 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 87.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 80.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (2022.6.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 74.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5->-r requirements.txt (line 2)) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->-r requirements.txt (line 7)) (4.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2->-r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.12.5->-r requirements.txt (line 2)) (3.0.9)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 79.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (1.7.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 5)) (2021.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.12.5->-r requirements.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5->-r requirements.txt (line 2)) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.5->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.5->-r requirements.txt (line 2)) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d232c650d8e09e970cff7dba31059618514d8e1bc5e882fa7f93fec1f994612d\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: torch, torchvision, tokenizers, sacremoses, ruamel.yaml.clib, huggingface-hub, transformers, timm, ruamel-yaml, pycocoevalcap\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed huggingface-hub-0.11.0 pycocoevalcap-1.2 ruamel-yaml-0.17.21 ruamel.yaml.clib-0.2.7 sacremoses-0.0.53 timm-0.4.9 tokenizers-0.10.3 torch-1.7.1 torchvision-0.8.2 transformers-4.12.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 125.1 MB/s eta 0:00:10tcmalloc: large alloc 1147494400 bytes == 0x3a40c000 @  0x7f8a9f2a7615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.3 MB/s eta 0:12:52tcmalloc: large alloc 1434370048 bytes == 0x7ea62000 @  0x7f8a9f2a7615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 100.5 MB/s eta 0:00:08tcmalloc: large alloc 1792966656 bytes == 0x3894000 @  0x7f8a9f2a7615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████▋       | 1566.5 MB 10.7 MB/s eta 0:00:45"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 110.2 MB/s eta 0:00:04tcmalloc: large alloc 2241208320 bytes == 0x6e67c000 @  0x7f8a9f2a7615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf3fde000 @  0x7f8a9f2a61e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x1e1f5a000 @  0x7f8a9f2a7615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.0 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 285 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.7.1\n",
            "    Uninstalling torch-1.7.1:\n",
            "      Successfully uninstalled torch-1.7.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.8.2\n",
            "    Uninstalling torchvision-0.8.2:\n",
            "      Successfully uninstalled torchvision-0.8.2\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlvqLkznm30l",
        "outputId": "89a9ad79-3270-4a0e-ebed-7a6dc66683cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPlMiUGkEBle",
        "outputId": "766c25a7-877e-4e5d-a5b5-a6d4451430b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/X-VLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d hsankesara/flickr-image-dataset"
      ],
      "metadata": {
        "id": "xAGqLJBpU1pw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "51cd726b-02e5-435c-9147-956a48d96bcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e1df6bfc-c057-4af7-92a8-799d22e0f165\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e1df6bfc-c057-4af7-92a8-799d22e0f165\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading flickr-image-dataset.zip to /content/X-VLM\n",
            "100% 8.15G/8.16G [00:49<00:00, 121MB/s]\n",
            "100% 8.16G/8.16G [00:49<00:00, 176MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"flickr-image-dataset.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"images/\")"
      ],
      "metadata": {
        "id": "QUdxQzcsY5CU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"images/flickr30k_images/flickr30k_images/\" \"images/flickr30k-images/\"\n",
        "!rm -rf \"images/flickr30k-images/flickr30k_images/\""
      ],
      "metadata": {
        "id": "LjvOetPhwe94"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "with tarfile.open(\"/content/drive/MyDrive/Colab Notebooks/DL1/finetune.tar\") as tar:\n",
        "    tar.extractall(\"data\")"
      ],
      "metadata": {
        "id": "357yv6c4xzKd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/DL1/checkpoint_best.pth\" \"checkpoints/\""
      ],
      "metadata": {
        "id": "MaezvYMlblnW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output\n",
        "!mkdir output/itr_flickr"
      ],
      "metadata": {
        "id": "qx5Mv4rWAtfw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python3 run.py --task \"itr_flickr\" --dist \"gpu0\" --evaluate --output_dir \"output/itr_flickr\" --checkpoint \"/content/X-VLM/checkpoints/checkpoint_best.pth\"\n",
        "\n"
      ],
      "metadata": {
        "id": "0Xo_MrgjEEh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6826df-7706-4c65-98cb-3d7802807024"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNODES,  1\n",
            "NPROC_PER_NODE,  8\n",
            "MASTER_ADDR,  SET_IT\n",
            "MASTER_PORT,  12345\n",
            "NODE_RANK,  0\n",
            "### warning: the settings for distributed training is not filled (ignore this if you only use one node)\n",
            "### warning: you have not set the path to hadoop_bin (ignore this if you don't use HDFS)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:164: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  \"The module torch.distributed.launch is deprecated \"\n",
            "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
            "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
            "  entrypoint       : Retrieval.py\n",
            "  min_nodes        : 1\n",
            "  max_nodes        : 1\n",
            "  nproc_per_node   : 1\n",
            "  run_id           : none\n",
            "  rdzv_backend     : static\n",
            "  rdzv_endpoint    : 127.0.0.1:29500\n",
            "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
            "  max_restarts     : 3\n",
            "  monitor_interval : 5\n",
            "  log_dir          : None\n",
            "  metrics_cfg      : {}\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_6lgi7158/none_ds7v19be\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=0\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_6lgi7158/none_ds7v19be/attempt_0/0/error.json\n",
            "2022-11-24 10:10:05.901738: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "| distributed init (rank 0): env://\n",
            "[W ProcessGroupNCCL.cpp:1569] Rank 0 using best-guess GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device.\n",
            "Creating model\n",
            "load checkpoint from /content/X-VLM/checkpoints/checkpoint_best.pth\n",
            "missing_keys:  []\n",
            "unexpected_keys:  []\n",
            "### Total Params:  213959547\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 3.11MB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 35.6kB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 6.23MB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 667kB/s]\n",
            "Creating retrieval dataset\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:835: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "### output_dir,  output/itr_flickr\n",
            "Start evaluating\n",
            "### be careful: func create_loader returns a list length of 1\n",
            "Computing features for evaluation...\n",
            "Evaluation: [   0/1000]  eta: 0:00:13    time: 0.0137  data: 0.0008  max mem: 3803\n",
            "Evaluation: [  50/1000]  eta: 0:00:20    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 100/1000]  eta: 0:00:19    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 150/1000]  eta: 0:00:18    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 200/1000]  eta: 0:00:17    time: 0.0220  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 250/1000]  eta: 0:00:16    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 300/1000]  eta: 0:00:15    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 350/1000]  eta: 0:00:14    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 400/1000]  eta: 0:00:12    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 450/1000]  eta: 0:00:11    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 500/1000]  eta: 0:00:10    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 550/1000]  eta: 0:00:09    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 600/1000]  eta: 0:00:08    time: 0.0217  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 650/1000]  eta: 0:00:07    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 700/1000]  eta: 0:00:06    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 750/1000]  eta: 0:00:05    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 800/1000]  eta: 0:00:04    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 850/1000]  eta: 0:00:03    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 900/1000]  eta: 0:00:02    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 950/1000]  eta: 0:00:01    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 999/1000]  eta: 0:00:00    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: Total time: 0:00:21 (0.0215 s / it)\n",
            "Evaluation: [   0/5000]  eta: 0:01:12    time: 0.0145  data: 0.0034  max mem: 3803\n",
            "Evaluation: [  50/5000]  eta: 0:01:46    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 100/5000]  eta: 0:01:45    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 150/5000]  eta: 0:01:44    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 200/5000]  eta: 0:01:43    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 250/5000]  eta: 0:01:42    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 300/5000]  eta: 0:01:41    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 350/5000]  eta: 0:01:40    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 400/5000]  eta: 0:01:39    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 450/5000]  eta: 0:01:38    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 500/5000]  eta: 0:01:36    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 550/5000]  eta: 0:01:35    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 600/5000]  eta: 0:01:34    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 650/5000]  eta: 0:01:33    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 700/5000]  eta: 0:01:32    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 750/5000]  eta: 0:01:31    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 800/5000]  eta: 0:01:30    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 850/5000]  eta: 0:01:29    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 900/5000]  eta: 0:01:28    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [ 950/5000]  eta: 0:01:27    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1000/5000]  eta: 0:01:26    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1050/5000]  eta: 0:01:24    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1100/5000]  eta: 0:01:23    time: 0.0219  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1150/5000]  eta: 0:01:22    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1200/5000]  eta: 0:01:21    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1250/5000]  eta: 0:01:20    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1300/5000]  eta: 0:01:19    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1350/5000]  eta: 0:01:18    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1400/5000]  eta: 0:01:17    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1450/5000]  eta: 0:01:16    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1500/5000]  eta: 0:01:15    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1550/5000]  eta: 0:01:14    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1600/5000]  eta: 0:01:13    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1650/5000]  eta: 0:01:12    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1700/5000]  eta: 0:01:11    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1750/5000]  eta: 0:01:09    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1800/5000]  eta: 0:01:08    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1850/5000]  eta: 0:01:07    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1900/5000]  eta: 0:01:06    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [1950/5000]  eta: 0:01:05    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2000/5000]  eta: 0:01:04    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2050/5000]  eta: 0:01:03    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2100/5000]  eta: 0:01:02    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2150/5000]  eta: 0:01:01    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2200/5000]  eta: 0:01:00    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2250/5000]  eta: 0:00:59    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2300/5000]  eta: 0:00:58    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2350/5000]  eta: 0:00:56    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2400/5000]  eta: 0:00:55    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2450/5000]  eta: 0:00:54    time: 0.0217  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2500/5000]  eta: 0:00:53    time: 0.0218  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2550/5000]  eta: 0:00:52    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2600/5000]  eta: 0:00:51    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2650/5000]  eta: 0:00:50    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2700/5000]  eta: 0:00:49    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2750/5000]  eta: 0:00:48    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2800/5000]  eta: 0:00:47    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2850/5000]  eta: 0:00:46    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2900/5000]  eta: 0:00:45    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [2950/5000]  eta: 0:00:44    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3000/5000]  eta: 0:00:43    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3050/5000]  eta: 0:00:41    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3100/5000]  eta: 0:00:40    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3150/5000]  eta: 0:00:39    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3200/5000]  eta: 0:00:38    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3250/5000]  eta: 0:00:37    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3300/5000]  eta: 0:00:36    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3350/5000]  eta: 0:00:35    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3400/5000]  eta: 0:00:34    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3450/5000]  eta: 0:00:33    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3500/5000]  eta: 0:00:32    time: 0.0216  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3550/5000]  eta: 0:00:31    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3600/5000]  eta: 0:00:30    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3650/5000]  eta: 0:00:29    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3700/5000]  eta: 0:00:27    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3750/5000]  eta: 0:00:26    time: 0.0214  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3800/5000]  eta: 0:00:25    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3850/5000]  eta: 0:00:24    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3900/5000]  eta: 0:00:23    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [3950/5000]  eta: 0:00:22    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4000/5000]  eta: 0:00:21    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4050/5000]  eta: 0:00:20    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4100/5000]  eta: 0:00:19    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4150/5000]  eta: 0:00:18    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4200/5000]  eta: 0:00:17    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4250/5000]  eta: 0:00:16    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4300/5000]  eta: 0:00:15    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4350/5000]  eta: 0:00:13    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4400/5000]  eta: 0:00:12    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4450/5000]  eta: 0:00:11    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4500/5000]  eta: 0:00:10    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4550/5000]  eta: 0:00:09    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4600/5000]  eta: 0:00:08    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4650/5000]  eta: 0:00:07    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4700/5000]  eta: 0:00:06    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4750/5000]  eta: 0:00:05    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4800/5000]  eta: 0:00:04    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4850/5000]  eta: 0:00:03    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4900/5000]  eta: 0:00:02    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4950/5000]  eta: 0:00:01    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: [4999/5000]  eta: 0:00:00    time: 0.0215  data: 0.0000  max mem: 3803\n",
            "Evaluation: Total time: 0:01:47 (0.0215 s / it)\n",
            "Evaluation time 0:02:16\n",
            "{'txt_r1': 97.1, 'txt_r5': 100.0, 'txt_r10': 100.0, 'txt_r_mean': 99.03333333333335, 'img_r1': 86.88, 'img_r5': 97.32, 'img_r10': 98.68, 'img_r_mean': 94.29333333333334, 'r_mean': 96.66333333333334}\n",
            "### Time 0:02:16\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
            "INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
            "INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0003521442413330078 seconds\n",
            "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"694\", \"role\": \"default\", \"hostname\": \"e74cab9b9f5b\", \"state\": \"SUCCEEDED\", \"total_run_time\": 155, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [1]}\", \"agent_restarts\": 0}}\n",
            "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"e74cab9b9f5b\", \"state\": \"SUCCEEDED\", \"total_run_time\": 155, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\"}\", \"agent_restarts\": 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../\n",
        "!pwd \n",
        "!git clone https://github.com/ShaharLutatiPersonal/OCD.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pqYKbuJDc6c",
        "outputId": "644976ca-6224-4d2a-9e6f-b742fa9b1e18"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OCD'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/28)\u001b[K\rremote: Counting objects:   7% (2/28)\u001b[K\rremote: Counting objects:  10% (3/28)\u001b[K\rremote: Counting objects:  14% (4/28)\u001b[K\rremote: Counting objects:  17% (5/28)\u001b[K\rremote: Counting objects:  21% (6/28)\u001b[K\rremote: Counting objects:  25% (7/28)\u001b[K\rremote: Counting objects:  28% (8/28)\u001b[K\rremote: Counting objects:  32% (9/28)\u001b[K\rremote: Counting objects:  35% (10/28)\u001b[K\rremote: Counting objects:  39% (11/28)\u001b[K\rremote: Counting objects:  42% (12/28)\u001b[K\rremote: Counting objects:  46% (13/28)\u001b[K\rremote: Counting objects:  50% (14/28)\u001b[K\rremote: Counting objects:  53% (15/28)\u001b[K\rremote: Counting objects:  57% (16/28)\u001b[K\rremote: Counting objects:  60% (17/28)\u001b[K\rremote: Counting objects:  64% (18/28)\u001b[K\rremote: Counting objects:  67% (19/28)\u001b[K\rremote: Counting objects:  71% (20/28)\u001b[K\rremote: Counting objects:  75% (21/28)\u001b[K\rremote: Counting objects:  78% (22/28)\u001b[K\rremote: Counting objects:  82% (23/28)\u001b[K\rremote: Counting objects:  85% (24/28)\u001b[K\rremote: Counting objects:  89% (25/28)\u001b[K\rremote: Counting objects:  92% (26/28)\u001b[K\rremote: Counting objects:  96% (27/28)\u001b[K\rremote: Counting objects: 100% (28/28)\u001b[K\rremote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 130 (delta 22), reused 19 (delta 19), pack-reused 102\u001b[K\n",
            "Receiving objects: 100% (130/130), 69.58 MiB | 49.89 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd OCD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQE_xc16EMkJ",
        "outputId": "c43f314b-8017-415c-c3a8-3788e190514d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OCD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_func_OCD.py -e 1 -t 0 -pd ./checkpoints/model_ocd_tinynerf.pt -ps ./checkpoints/scale_model_tinynerf.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwglmLKqEWqb",
        "outputId": "97aca8dd-933a-45f2-8f6d-c4e8fb27eb89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n",
            "100% 507M/507M [00:03<00:00, 156MB/s]\n",
            "Namespace(backbone_path='./base_models/checkpoint_tinynerf.pt', config_path='./configs/train_tinynerf.json', data_test_path='/data', data_train_path='./data/tiny_nerf_data.npz', datatype='tinynerf', diffusion_model_path='./checkpoints/model_ocd_tinynerf.pt', eval=1, learning_rate=0.0002, precompute_all=1, resume_training=0, scale_model_path='./checkpoints/scale_model_tinynerf.pt', tensorboard_path='./logs', train=0)\n",
            "2022-11-24 10:13:26.270238: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "[[0, 0], [33, 32]]\n",
            "****************************************************************************************************\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Baseline loss 0.0075836824253201485, Overfitted loss 0.005036868155002594, Diffusion loss 0.005745356436818838"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2WEtFo8LIJHl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}